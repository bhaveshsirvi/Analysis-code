{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file calculates the s-weights and does the random best candidate selection, and converts them to a root file which serves as an input to the fitting framework LAURA++.\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet converts the n-tuples into a pandas dataframe for easier manipulation. Selectiom cuts have already been applied to the n-tuples in the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from plot_function import plot,dalitz\n",
    "from sweights import kendall_tau # for an independence test\n",
    "from sweights import plot_indep_scatter\n",
    "from iminuit.pdg_format import pdg_format\n",
    "import ROOT\n",
    "from ROOT import TH1F, RooRealVar, RooDataHist, RooArgList, RooGaussian, RooArgusBG, RooAddPdf, RooFit\n",
    "import warnings\n",
    "import uproot\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "#In my analysis I seperated individual components of the signal.\n",
    "sig = pd.concat([pd.read_csv('d0_new.csv'),pd.read_csv('d2_new.csv'),pd.read_csv('nores_new.csv')])\n",
    "bkg = pd.concat([pd.read_csv('charged_background_final.csv'),pd.read_csv('mixed_background_final.csv'),pd.read_csv('continumm_all_final.csv')])\n",
    "\n",
    "data_df=pd.concat([sig, bkg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you have not yet processed the n-tuples for example do the pion sorting (based on momentum) the following code would be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "\n",
    "df = uproot.open(\"name-of-your-rootfile.root\")[\"tree\"].arrays(library=\"pd\")\n",
    "\n",
    "#Random best candidate selection\n",
    "\n",
    "grouped = df.groupby(['__experiment__', '__run__', '__event__','__production__'])\n",
    "def select_random_candidate(group):\n",
    "    return group.sample(n=1)\n",
    "random_candidates = grouped.apply(select_random_candidate).reset_index(drop=True)\n",
    "\n",
    "df_1 = random_candidates\n",
    "\n",
    "for index, row in df_1.iterrows():\n",
    "    # Create TLorentzVector for the B meson, pim11, and pim12\n",
    "    vector_B_meson = ROOT.TLorentzVector(row['B1_mcPX'], row['B1_mcPY'], row['B1_mcPZ'], row['B1_mcE'])\n",
    "    vector_pim11 = ROOT.TLorentzVector(row['pim11_mcPX'], row['pim11_mcPY'], row['pim11_mcPZ'], row['pim11_mcE'])\n",
    "    vector_pim12 = ROOT.TLorentzVector(row['pim12_mcPX'], row['pim12_mcPY'], row['pim12_mcPZ'], row['pim12_mcE'])\n",
    "\n",
    "    # Calculate the boost vector for the B meson's rest frame\n",
    "    boost_vector = -vector_B_meson.BoostVector()  # Negative because we want the boost in the opposite direction\n",
    "\n",
    "    # Boost pim11 and pim12 to the B meson's rest frame\n",
    "    vector_pim11.Boost(boost_vector)\n",
    "    vector_pim12.Boost(boost_vector)\n",
    "\n",
    "    # Extract the boosted momenta\n",
    "    momentum_pim11 = vector_pim11.P() \n",
    "    momentum_pim12= vector_pim12.P()  \n",
    "    \n",
    "    # Add the boosted momenta back to the df\n",
    "    df_1.at[index, 'boosted_pim11_p'] = momentum_pim11\n",
    "    df_1.at[index, 'boosted_pim12_p'] = momentum_pim12\n",
    "    \n",
    "\n",
    "#Sort pions based on momentum pim12_p > pim11_p\n",
    "pim11_cols = [col for col in df_1.columns if col.startswith('pim11_')]\n",
    "pim12_cols = [col for col in df_1.columns if col.startswith('pim12_')]\n",
    "\n",
    "A = df_1.copy()\n",
    "\n",
    "for i, row in df_1.iterrows():\n",
    "    if row['boosted_pim12_p'] > row['boosted_pim11_p']:\n",
    "        for pim11_col, pim12_col in zip(pim11_cols, pim12_cols):\n",
    "            A.at[i, pim11_col], A.at[i, pim12_col] = row[pim12_col], row[pim11_col]            \n",
    "         \n",
    "\n",
    "#Calculate the DP variables\n",
    "A['mdpluspim112'] = (A['Dplus_mcE'] + A['pim11_mcE'])**2 - (A['Dplus_mcPX'] + A['pim11_mcPX'])**2 - (A['Dplus_mcPY'] + A['pim11_mcPY'])**2 - (A['Dplus_mcPZ'] + A['pim11_mcPZ'])**2\n",
    "A['mdpluspim122'] = (A['Dplus_mcE'] + A['pim12_mcE'])**2 - (A['Dplus_mcPX'] + A['pim12_mcPX'])**2 - (A['Dplus_mcPY'] + A['pim12_mcPY'])**2 - (A['Dplus_mcPZ'] + A['pim12_mcPZ'])**2\n",
    "A['mpim11pim122'] = (A['pim11_mcE'] + A['pim12_mcE'])**2 - (A['pim11_mcPX'] + A['pim12_mcPX'])**2 - (A['pim11_mcPY'] + A['pim12_mcPY'])**2 - (A['pim11_mcPZ'] + A['pim12_mcPZ'])**2\n",
    "\n",
    "\n",
    "A['mpim11pim12min'] = A['pim12_M'] + A['pim11_M']\n",
    "A['mpim11pim12max'] = A['B1_M'] - A['Dplus_M']\n",
    "\n",
    "\n",
    "#mprime \n",
    "A['mprime'] = (1/np.pi)*np.arccos(((2*(np.sqrt(A['mpim11pim122']) - A['mpim11pim12min']))/(A['mpim11pim12max'] - A['mpim11pim12min']))-1)\n",
    "\n",
    "#Calculating the helicity angle (refer to lhcb paper on Amplitude analysis of B-->D+pi-pi- for exact definition)\n",
    "\n",
    "def thprime(row):\n",
    "    # Create TLorentzVector for particles D, B (pi_minus_1), and C (pi_minus_2)\n",
    "    vector_D = ROOT.TLorentzVector(row['Dplus_mcPX'], row['Dplus_mcPY'], row['Dplus_mcPZ'], row['Dplus_mcE'])\n",
    "    vector_B = ROOT.TLorentzVector(row['pim11_mcPX'], row['pim11_mcPY'], row['pim11_mcPZ'], row['pim11_mcE'])\n",
    "    vector_C = ROOT.TLorentzVector(row['pim12_mcPX'], row['pim12_mcPY'], row['pim12_mcPZ'], row['pim12_mcE'])\n",
    "\n",
    "    # Calculate the combined momentum of the pi-p- system (vector_B + vector_C)\n",
    "    vector_pi_pi = vector_B + vector_C\n",
    "\n",
    "    # Boost vectors D, B, and C into the pi-p- rest frame\n",
    "    boost_vector = -vector_pi_pi.BoostVector()  # Negative because we want the boost in the opposite direction\n",
    "    vector_D.Boost(boost_vector)\n",
    "    vector_B.Boost(boost_vector)\n",
    "    vector_C.Boost(boost_vector) \n",
    "\n",
    "    # Calculate the helicity angle, which is the angle between the D meson and one of the pions in the pi-p-rest frame\n",
    "    cos_theta = vector_D.Vect().Dot(vector_C.Vect()) / (vector_D.Vect().Mag() * vector_C.Vect().Mag())\n",
    "    theta = ROOT.TMath.ACos(cos_theta)\n",
    "    \n",
    "    # Return the angle in radians divided by pi\n",
    "    return (1/ROOT.TMath.Pi())*theta \n",
    "\n",
    "A['thprime'] = A.apply(thprime, axis=1)\n",
    "\n",
    "#Selection cuts (in the case of signal add an additional cut 'isSignal == 1')\n",
    "A = A.query('0.5 > thprime & (-0.025< deltaE < 0.025) & (Mbc > 5.27)&(5.26<M<5.30)&(1.85865<Dplus_M<1.88065)')\n",
    "\n",
    "#plotting\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "plt.figure(figsize=(15, 9))\n",
    "\n",
    "plt.xlabel(r'$M_{D^+ \\pi_{fast}^-}^{2}$ [$GeV^2$]',fontsize=18)\n",
    "plt.ylabel(r'$M_{D^+ \\pi_{slow}^-}^{2}$[$GeV^2$]',fontsize=18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.tick_params(axis='both', which='minor', length=4, color='b')\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(4)) \n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(4))  \n",
    "\n",
    "plt.scatter(A['mdpluspim112'],A['mdpluspim122'],s=0.5,c= 'black') \n",
    "\n",
    "\n",
    "#If we are working on the charged collection which contains the signal events we can seperate the signal into it's different components using 'component_genMotherPDG' flag\n",
    "d0 = A.query('pim12_genMotherPDG==10421 | pim12_genMotherPDG == -10421 | pim11_genMotherPDG==10421 | pim11_genMotherPDG == -10421')\n",
    "d2 = A.query('pim12_genMotherPDG==425.0 | pim12_genMotherPDG == -425.0 | pim11_genMotherPDG==425.0 | pim11_genMotherPDG == -425.0')\n",
    "nores = A.query('pim12_genMotherPDG == 521.0 | pim12_genMotherPDG == -521.0')\n",
    "\n",
    "#All events from other collections (and events with isSignal==0 from charged collections) are considered as background\n",
    "\n",
    "#d2.to_csv('d2_final.csv',index=False)\n",
    "#d0.to_csv('d0_final.csv',index=False)\n",
    "#nores.to_csv('nores_final.csv',index=False)\n",
    "#bkg.to_csv('charged_background.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets contain the calculation of s-weights. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following checks for co-relation between the discriminating variable (Mbc) and the DP variables\n",
    "\n",
    "toy = np.stack((data_df['mdpluspim122'].to_numpy(), data_df['Mbc'].to_numpy()), axis=1)\n",
    "kts = kendall_tau(toy[:, 0], toy[:, 1])\n",
    "scatter = plt.scatter(toy[:, 0], toy[:, 1], s=0.2) \n",
    "plt.xlabel(r'$m(D\\pi)^2_{max}$ [$GeV^2$]', fontsize=18)\n",
    "plt.ylabel('Mbc [GeV]', fontsize=18)\n",
    "plt.legend([r'$\\tau$ = {:.3f}'.format(kts[0])], frameon=False, fontsize=10,loc=\"upper right\")\n",
    "plt.minorticks_on() \n",
    "plt.tick_params(axis='both', which='major', labelsize=14) \n",
    "plt.tick_params(axis='both', which='minor', labelsize=10) \n",
    "#plt.savefig('kendalltaumdplusmax.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now fit Gaussian and Argus for signal and bkg respectively for Mbc. \n",
    "\n",
    "Mbc = RooRealVar('Mbc', 'Mbc [GeV]', 5.27, 5.29)\n",
    "\n",
    "# Add data to the histogram\n",
    "hist = TH1F(\"hist\", \"Mbc Distribution\", 500, 5.27, 5.29)\n",
    "for value in data_df['Mbc']:\n",
    "    hist.Fill(value)\n",
    "\n",
    "# Convert the histogram to a RooDataHist for fitting\n",
    "data = RooDataHist('data', 'Dataset with Mbc', RooArgList(Mbc), hist)\n",
    "\n",
    "#Yield Variables\n",
    "n_signal = RooRealVar('n_signal', 'Number of signal events', len(sig)-50, 0, len(sig)+800)\n",
    "n_background = RooRealVar('n_background', 'Number of background events', len(bkg)-20, 0, len(bkg)+800)\n",
    "\n",
    "# Signal PDF: Gaussian\n",
    "mu_sig = RooRealVar('mu_sig', 'Mean of Gaussian', 5.27928, 5.26, 5.30)\n",
    "sigma_sig = RooRealVar('sigma_sig', 'Width of Gaussian', 0.00286059, 0.001, 0.010)\n",
    "signal_pdf = RooGaussian('gaussian_signal', 'Gaussian Signal Model', Mbc, mu_sig, sigma_sig)\n",
    "\n",
    "# Background PDF: Argus\n",
    "cutoff = RooRealVar(\"cutoff\", \"Cutoff of Argus\", 5.28958, 5.26, 5.29)\n",
    "shape = RooRealVar(\"shape\", \"Shape parameter of Argus\", -20.8491, -100, 0)\n",
    "bkg_pdf = RooArgusBG(\"argus_bg\", \"Argus Background\", Mbc, cutoff, shape)\n",
    "\n",
    "# Fit model\n",
    "model = RooAddPdf('model', 'Signal + Background', RooArgList(signal_pdf, bkg_pdf), RooArgList(n_signal, n_background))\n",
    "fit_result = model.fitTo(data, RooFit.Save())\n",
    "\n",
    "# Plot the result\n",
    "frame = Mbc.frame()\n",
    "data.plotOn(frame)\n",
    "model.plotOn(frame)\n",
    "model.plotOn(frame, RooFit.Components('gaussian_signal'), RooFit.LineColor(ROOT.kRed), RooFit.LineStyle(ROOT.kDashed))\n",
    "model.plotOn(frame, RooFit.Components('argus_bg'), RooFit.LineColor(ROOT.kGreen), RooFit.LineStyle(ROOT.kDashed))\n",
    "\n",
    "%jsroot on\n",
    "canvas = ROOT.TCanvas()\n",
    "frame.Draw()\n",
    "canvas.Draw()\n",
    "\n",
    "canvas.SaveAs(\"Mbc_fit_high_res.png\") \n",
    "canvas.SaveAs(\"Mbc_fit_high_res.pdf\")\n",
    "\n",
    "# Extract yields\n",
    "n_signal = fit_result.floatParsFinal().find('n_signal').getVal()\n",
    "n_background = fit_result.floatParsFinal().find('n_background').getVal()\n",
    "chi2 = frame.chiSquare()\n",
    "print(f\"Chi^2 value of the fit: {chi2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the s-weights\n",
    "from sweights import SWeight, convert_rf_pdf\n",
    "\n",
    "df_sw = data_df['Mbc'].to_numpy()\n",
    "\n",
    "# Convert the PDFs from RooFit to Python callables\n",
    "SigPDF = convert_rf_pdf(signal_pdf, Mbc)\n",
    "BkgPDF = convert_rf_pdf(bkg_pdf, Mbc)\n",
    "\n",
    "# Calculate the sWeights\n",
    "sweighter = SWeight(df_sw, [SigPDF, BkgPDF], [n_signal, n_background],\n",
    "                    [(5.27, 5.29)], method=\"summation\", verbose=True, checks=True)\n",
    "\n",
    "# Add the sWeights to your df\n",
    "data_df[\"SigWeight\"] = sweighter.get_weight(0, df_sw)\n",
    "data_df[\"BkgWeight\"] = sweighter.get_weight(1, df_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the weights \n",
    "\n",
    "plt.style.use('default')\n",
    "range_min, range_max = -2.2, 2\n",
    "bins = 50\n",
    "bin_width = (range_max - range_min) / bins \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(data_df['SigWeight'], bins=bins, range=[range_min, range_max], alpha=0.5, label='Signal')\n",
    "ax.hist(data_df['BkgWeight'], bins=bins, range=[range_min, range_max], alpha=0.5, label='Background')\n",
    "\n",
    "ax.set_xlabel(r'$sWeight$', fontsize=18)\n",
    "ax.set_ylabel(f'Events / {bin_width:.2f}', fontsize=18) \n",
    "\n",
    "# Add legend and other plot settings\n",
    "ax.legend(frameon=False, fontsize=14)\n",
    "ax.minorticks_on()\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "plt.xlim(-2,2)\n",
    "fig.gca().grid(False)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.savefig('weightsdistribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplying the weights to the signal along with the pull distribution\n",
    "\n",
    "bins = 50\n",
    "range_min, range_max = data_df['mdpluspim122'].min(), data_df['mdpluspim122'].max()  \n",
    "bin_width = (range_max - range_min) / bins  \n",
    "\n",
    "\n",
    "weighted_counts, bin_edges = np.histogram(data_df['mdpluspim122'], bins=bins, range=(range_min, range_max), weights=data_df['SigWeight'])\n",
    "pure_signal_counts, _ = np.histogram(sig['mdpluspim122'], bins=bin_edges)\n",
    "\n",
    "# Calculate pulls based on the given formula:\n",
    "# pull_i = (N_fitted - N_generated) / sqrt(N_fitted)\n",
    "pulls = np.divide(weighted_counts - pure_signal_counts, np.sqrt(weighted_counts), where=(weighted_counts != 0))\n",
    "\n",
    "fig, (ax_main, ax_pull) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [3, 1]}, figsize=(12, 9), sharex=True)\n",
    "\n",
    "ax_main.hist(data_df['mdpluspim122'],bins=bins, range=(range_min, range_max), weights=data_df['SigWeight'], histtype='step', color='red', linewidth=1.5, label='Background subtracted signal')\n",
    "ax_main.hist(sig['mdpluspim122'],bins=bins, range=(range_min, range_max), histtype='step', color='blue', linewidth=1.5, label='Pure signal')\n",
    "ax_main.set_ylabel(fr'Events / {bin_width:.2f} $GeV^2$', fontsize=14)\n",
    "ax_main.legend(frameon=False, fontsize=12)\n",
    "\n",
    "# Plot the pull distribution\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  \n",
    "ax_pull.bar(bin_centers, pulls, width=bin_width, edgecolor='black', label='Pull (Weighted - Pure) / sqrt(Weighted)')\n",
    "ax_pull.set_xlabel(r'$m(D\\pi)^2_{max}$ [$GeV^2$]', fontsize=14)\n",
    "ax_pull.set_ylabel('Pull', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('weighted_vs_pure_signal_with_pulls.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dataframe to root file which will serve as an input to LAURA++\n",
    "\n",
    "# data_df = A \n",
    "data_df['iExpt'] = 0  #Experiment number\n",
    "data = {\n",
    "    'm13Sq': data_df['mdpluspim122'],\n",
    "    'm23Sq': data_df['mdpluspim112'],\n",
    "    'm12Sq': data_df['mpim11pim122'],\n",
    "    'm13': data_df['mdpluspim122']**0.5,\n",
    "    'm23': data_df['mdpluspim112']**0.5,\n",
    "    'm12': data_df['mpim11pim122']**0.5,\n",
    "    'evtWeight' : data_df['SigWeight'],\n",
    "    'mPrime' : data_df['mprime'],\n",
    "    'thPrime' : data_df['thprime'],\n",
    "    'iExpt' : data_df['iExpt']   \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df = df.reset_index(drop=True)\n",
    "arrays = {name: df[name].values for name in df.columns}\n",
    "\n",
    "with uproot.recreate('output-root-file.root') as f:\n",
    "    f['tree'] = arrays"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
