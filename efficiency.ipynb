{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the calculation of efficiency histogram which will also serve as an input to LAURA++. The parallelization strategy of the dataframe is necessary as we need to generate a lot of generator level events to lower the uncertainity on the efficiency (and also so that the generated events cover the entire DP, so we could achieve a much finer binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import dask.dataframe as dd\n",
    "import ROOT\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy.interpolate import RectBivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open(\"generated-output.root\")\n",
    "tree = file[\"tree;1\"]\n",
    "columns_to_read = ['isSignal', 'B1_deltaE', 'M', 'Dplus_M','__event__', '__production__',\n",
    "                  '__ncandidates__','B1_mcPX', 'B1_mcPY', 'B1_mcPZ', 'B1_mcE',\n",
    "                  'pim11_mcPX', 'pim11_mcPY', 'pim11_mcPZ', 'pim11_mcE',\n",
    "                  'pim12_mcPX', 'pim12_mcPY', 'pim12_mcPZ','pim12_mcE',\n",
    "                  'Dplus_mcPX', 'Dplus_mcPY', 'Dplus_mcPZ','Dplus_mcE',\n",
    "                  'pim12_M','pim11_M','B1_M']\n",
    "df = tree.arrays(expressions=columns_to_read, library=\"pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random best candidate selection \n",
    "# Parallelize the dataframe using dask and divide the dataframes into two dataframes, one with 2 candidates and one with 1 candidate.\n",
    "\n",
    "df = dd.from_pandas(pd.concat([df]), npartitions=20)\n",
    " \n",
    "df_filtered = df[df['__ncandidates__'] == 2]\n",
    "\n",
    "grouped = df_filtered.groupby(['__event__', '__production__'])\n",
    "\n",
    "def select_random_candidate(group):\n",
    "    return group.sample(frac=1).head(1)\n",
    "\n",
    "random_candidates = grouped.apply(select_random_candidate,meta = df_filtered.dtypes.to_dict()).reset_index(drop=True)\n",
    "\n",
    "df_single_candidates = df[df['__ncandidates__'] == 1]\n",
    "\n",
    "final = dd.concat([random_candidates, df_single_candidates])\n",
    "\n",
    "df_1 = final.compute()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def calculate_momentum_partition(df):\n",
    "    # Initialize empty lists to store the boosted momenta\n",
    "    boosted_pim11_p = []\n",
    "    boosted_pim12_p = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Create TLorentzVector for the B meson\n",
    "        vector_B_meson = ROOT.TLorentzVector(row['B1_mcPX'], row['B1_mcPY'], row['B1_mcPZ'], row['B1_mcE'])\n",
    "\n",
    "        # Create TLorentzVector for pim11 and pim12\n",
    "        vector_pim11 = ROOT.TLorentzVector(row['pim11_mcPX'], row['pim11_mcPY'], row['pim11_mcPZ'], row['pim11_mcE'])\n",
    "        vector_pim12 = ROOT.TLorentzVector(row['pim12_mcPX'], row['pim12_mcPY'], row['pim12_mcPZ'], row['pim12_mcE'])\n",
    "\n",
    "        # Calculate the boost vector for the B meson's rest frame\n",
    "        boost_vector = -vector_B_meson.BoostVector()\n",
    "\n",
    "        # Boost pim11 and pim12 to the B meson's rest frame\n",
    "        vector_pim11.Boost(boost_vector)\n",
    "        vector_pim12.Boost(boost_vector)\n",
    "\n",
    "        # Extract the boosted momenta and append to the lists\n",
    "        boosted_pim11_p.append(vector_pim11.P())\n",
    "        boosted_pim12_p.append(vector_pim12.P())\n",
    "\n",
    "    # Create a new DataFrame with the boosted momenta\n",
    "    result_df = pd.DataFrame({'boosted_pim11_p': boosted_pim11_p, 'boosted_pim12_p': boosted_pim12_p})\n",
    "    return result_df\n",
    "\n",
    "\n",
    "#Original dataframe to dask df\n",
    "ddf = dd.from_pandas(df_1, npartitions=10)\n",
    "\n",
    "# Apply the function to each partition of the dask df\n",
    "momenta = ddf.map_partitions(calculate_momentum_partition, meta={'boosted_pim11_p': 'float64', 'boosted_pim12_p': 'float64'})\n",
    "\n",
    "momenta_reset = momenta.reset_index(drop=True)\n",
    "ddf_reset = ddf.reset_index(drop=True)\n",
    "\n",
    "# Now concatenate along columns\n",
    "A = dd.concat([momenta_reset, ddf_reset], axis=1)\n",
    "\n",
    "# Calculating DP variables\n",
    "A['mdpluspim112'] = (A['Dplus_mcE'] + A['pim11_mcE'])**2 - (A['Dplus_mcPX'] + A['pim11_mcPX'])**2 - (A['Dplus_mcPY'] + A['pim11_mcPY'])**2 - (A['Dplus_mcPZ'] + A['pim11_mcPZ'])**2\n",
    "A['mdpluspim122'] = (A['Dplus_mcE'] + A['pim12_mcE'])**2 - (A['Dplus_mcPX'] + A['pim12_mcPX'])**2 - (A['Dplus_mcPY'] + A['pim12_mcPY'])**2 - (A['Dplus_mcPZ'] + A['pim12_mcPZ'])**2\n",
    "A['mpim11pim122'] = (A['pim11_mcE'] + A['pim12_mcE'])**2 - (A['pim11_mcPX'] + A['pim12_mcPX'])**2 - (A['pim11_mcPY'] + A['pim12_mcPY'])**2 - (A['pim11_mcPZ'] + A['pim12_mcPZ'])**2\n",
    "\n",
    "final_ddf = A[['boosted_pim11_p', 'boosted_pim12_p', 'mdpluspim112', 'mdpluspim122','mpim11pim122','M','pim12_M','pim11_M','B1_M','Dplus_M',\n",
    "               'Dplus_mcPX','Dplus_mcPY', 'Dplus_mcPZ','Dplus_mcE',\n",
    "               'pim11_mcPX', 'pim11_mcPY', 'pim11_mcPZ','pim11_mcE',\n",
    "               'pim12_mcPX', 'pim12_mcPY', 'pim12_mcPZ','pim12_mcE']]\n",
    "\n",
    "def swap_columns_in_partition(df):\n",
    "    # Identify columns starting with 'mdpluspim112' and 'mdpluspim122'\n",
    "    pim11_cols = [col for col in df.columns if col.startswith('mdpluspim112')]\n",
    "    pim12_cols = [col for col in df.columns if col.startswith('mdpluspim122')]\n",
    "    \n",
    "    # Iterate over the DataFrame rows\n",
    "    for i, row in df.iterrows():\n",
    "        # Check the condition to swap values\n",
    "        if row['boosted_pim12_p'] > row['boosted_pim11_p']:\n",
    "            for pim11_col, pim12_col in zip(pim11_cols, pim12_cols):\n",
    "                # Swap the values\n",
    "                df.at[i, pim11_col], df.at[i, pim12_col] = row[pim12_col], row[pim11_col]\n",
    "                \n",
    "    return df\n",
    "\n",
    "sorted_final = final_ddf.map_partitions(swap_columns_in_partition, meta=final_ddf)\n",
    "\n",
    "B = sorted_final.compute()\n",
    "\n",
    "def helicity_angle(row):\n",
    "    # Create TLorentzVector for particles D, B (pi_minus_1), and C (pi_minus_2)\n",
    "    vector_D = ROOT.TLorentzVector(row['Dplus_mcPX'], row['Dplus_mcPY'], row['Dplus_mcPZ'], row['Dplus_mcE'])\n",
    "    vector_B = ROOT.TLorentzVector(row['pim11_mcPX'], row['pim11_mcPY'], row['pim11_mcPZ'], row['pim11_mcE'])\n",
    "    vector_C = ROOT.TLorentzVector(row['pim12_mcPX'], row['pim12_mcPY'], row['pim12_mcPZ'], row['pim12_mcE'])\n",
    "\n",
    "    # Calculate the combined momentum of the pi-p- system (vector_B + vector_C)\n",
    "    vector_pi_pi = vector_B + vector_C\n",
    "\n",
    "    # Boost vectors D, B, and C into the π−π− rest frame\n",
    "    boost_vector = -vector_pi_pi.BoostVector()  # Negative because we want the boost in the opposite direction\n",
    "    vector_D.Boost(boost_vector)\n",
    "    vector_B.Boost(boost_vector)\n",
    "    vector_C.Boost(boost_vector) \n",
    "\n",
    "    # Calculate the helicity angle, which is the angle between the D meson and one of the pions in the π−π− rest frame\n",
    "    cos_theta = vector_D.Vect().Dot(vector_C.Vect()) / (vector_D.Vect().Mag() * vector_C.Vect().Mag())\n",
    "    theta = ROOT.TMath.ACos(cos_theta)\n",
    "    \n",
    "    # Return the angle in radians divided by pi\n",
    "    return (1/ROOT.TMath.Pi())*theta \n",
    "\n",
    "B['mpim11pim12min'] = B['pim12_M'] + B['pim11_M']\n",
    "B['mpim11pim12max'] = B['B1_M'] - B['Dplus_M']\n",
    "B['thprime'] = B.apply(helicity_angle, axis=1)\n",
    "B['mprime'] = (1/np.pi)*np.arccos(((2*(np.sqrt(B['mpim11pim122']) - B['mpim11pim12min']))/(B['mpim11pim12max'] - B['mpim11pim12min']))-1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time taken: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the efficiency plot and interpolate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bina = 10\n",
    "bins = [bina, bina]  \n",
    "x_range = [0, 1]\n",
    "y_range = [0, 0.5]\n",
    "\n",
    "hist_A, xedges, yedges = np.histogram2d(rec['mprime'], rec['thprime'], bins=bins, range=[x_range, y_range])\n",
    "hist_nores, _, _ = np.histogram2d(gen['mprime'], gen['thprime'], bins=bins, range=[x_range, y_range])\n",
    "\n",
    "# Ratio calculation\n",
    "ratio = np.divide(hist_A, hist_nores, out=np.zeros_like(hist_nores), where=(hist_nores != 0))\n",
    "ratio[(hist_nores == 0) & (hist_A == 0)] = 0  \n",
    "\n",
    "# Midpoints for interpolation\n",
    "x_mid = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "y_mid = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "\n",
    "# Interpolation setup\n",
    "spline = RectBivariateSpline(x_mid, y_mid, ratio.T, kx=3, ky=3)\n",
    "\n",
    "X_fine = np.linspace(x_range[0], x_range[1], 400)\n",
    "Y_fine = np.linspace(y_range[0], y_range[1], 400)\n",
    "X_fine_grid, Y_fine_grid = np.meshgrid(X_fine, Y_fine)\n",
    "ratio_fine = spline.ev(X_fine_grid.ravel(), Y_fine_grid.ravel()).reshape(400, 400)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(ratio_fine.T, extent=(x_range[0], x_range[1], y_range[0], y_range[1]), origin='lower', aspect='auto', cmap='plasma', norm=LogNorm())\n",
    "cbar = plt.colorbar(img, label='Efficiency')\n",
    "cbar.ax.set_ylabel('Efficiency', rotation=270, labelpad=20, fontsize=20)\n",
    "cbar.ax.tick_params(labelsize=18)\n",
    "ax.set_xlabel(r'$m^{\\prime}$', fontsize=18)  \n",
    "ax.set_ylabel(r'$\\theta^{\\prime}$', fontsize=18)\n",
    "ax.minorticks_on()\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "ax.grid(False)\n",
    "plt.savefig('efficieincy_logscale.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the histogram to a ROOT file.\n",
    "file = ROOT.TFile(\"efficiency.root\", \"RECREATE\")\n",
    "hist_root = ROOT.TH2F(\"h_ratio\", \"Efficiency;M_{D^+ \\pi_{slow}^-}^{2} [GeV^2];M_{D^+ \\pi^-}^{2} [GeV^2]\", bins[0], x_range[0], x_range[1], bins[1], y_range[0], y_range[1])\n",
    "\n",
    "for i in range(bins[0]):\n",
    "    for j in range(bins[1]):\n",
    "        hist_root.SetBinContent(i + 1, j + 1, ratio_fine[i][j])\n",
    "\n",
    "hist_root.Write()\n",
    "file.Close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
